import os
import argparse
import pickle
import numpy as np
import mne
from datetime import datetime
import matplotlib.pyplot as plt
from pyriemann.classification import MDM
from Utils.preprocessing import concatenate_streams  # reuse from generate script
from Generate_Reimannian_COURSEPROJECT import load_and_merge_gdf, segment_epochs
from pyriemann.utils.mean import invsqrtm
from pyriemann.utils.geodesic import geodesic_riemann
from pyriemann.estimation import Shrinkage
from sklearn.covariance import LedoitWolf
import config


def classify_trial_sliding(
    raw, start_sample, end_sample, sfreq, model,
    window_size_sec=0.5, step_size_sec=1/16
):
    """
    Classify one trial using sliding windows and adaptive recentering.

    Parameters:
        raw: MNE Raw object (preloaded)
        start_sample: trial start (in samples)
        end_sample: trial end (in samples)
        sfreq: Sampling frequency
        model: Trained Riemannian classifier
        window_size_sec: window size in seconds
        step_size_sec: step size in seconds

    Returns:
        List of probabilities over time (for correct class)
    """


    # Pre-allocate
    proba_trace = []
    Prev_T = None
    counter = 0

    # Extract trial data from raw
    data = raw.get_data(start=start_sample, stop=end_sample)  # shape (n_channels, n_samples)
    n_samples = data.shape[1]
    window_samples = int(window_size_sec * sfreq)
    step_samples = int(step_size_sec * sfreq)

    for i in range(0, n_samples - window_samples + 1, step_samples):
        segment = data[:, i:i+window_samples]

        # Convert segment to MNE RawArray
        info = raw.info.copy()
        raw_segment = mne.io.RawArray(segment, info)

        # Drop mastoids if needed
        for ch in ["M1", "M2"]:
            if ch in raw_segment.ch_names:
                raw_segment.drop_channels([ch])

        # Filtering (Notch + Bandpass)
        raw_segment.notch_filter(60, method="iir")
        raw_segment.filter(8, 12, method="iir")

        # Select motor channels if needed
        if config.SELECT_MOTOR_CHANNELS:
            raw_segment = select_motor_channels(raw_segment)

        # Compute covariance
        X = raw_segment.get_data()
        cov = (X @ X.T) / np.trace(X @ X.T)

        # Apply shrinkage
        if config.LEDOITWOLF:
            cov = LedoitWolf().fit(cov).covariance_
        else:
            cov = Shrinkage(shrinkage=config.SHRINKAGE_PARAM).fit_transform(cov[np.newaxis, :, :])[0]

        # Adaptive recentering
        if config.RECENTERING:
            if counter == 0:
                Prev_T = cov
            T_test = geodesic_riemann(Prev_T, cov, 1 / (counter + 1))
            Prev_T = T_test
            counter += 1
            T_inv = invsqrtm(T_test)
            cov = T_inv @ cov @ T_inv.T

        cov = np.expand_dims(cov, axis=0)  # shape (1, channels, channels)
        probs = model.predict_proba(cov)[0]

        # Determine MI or REST trial
        correct_label = 200 if raw.annotations.description[start_sample] == '770' else 100
        class_index = np.where(model.classes_ == correct_label)[0][0]
        proba_trace.append(probs[class_index])

    return proba_trace



def main(model_dir, working_dir):
    """
    Pseudo-online replay of MI/REST decoding using a trained Riemannian classifier.

    Parameters:
        model_dir (str): Directory containing the trained .pkl decoder file.
        working_dir (str): Directory containing the GDF files to analyze.
    """
    from pyriemann.utils.geodesic import geodesic_riemann
    from pyriemann.utils.mean import invsqrtm
    from pyriemann.estimation import Shrinkage
    from sklearn.covariance import LedoitWolf

    mne.set_log_level("WARNING")
    print("üöÄ Starting pseudo-online analysis...")
    print(f"üìÅ Data Directory: {working_dir}")
    print(f"üì¶ Model Directory: {model_dir}")

    # üîç Locate model
    model_candidates = [f for f in os.listdir(model_dir) if f.endswith(".pkl")]
    if len(model_candidates) != 1:
        raise RuntimeError(f"üö® Expected exactly one .pkl model file in {model_dir}, found {len(model_candidates)}.")
    model_path = os.path.join(model_dir, model_candidates[0])
    print(f"üì¶ Using decoder model: {model_candidates[0]}")

    # Load model
    with open(model_path, 'rb') as f:
        decoder = pickle.load(f)
    print("‚úÖ Loaded trained decoder.")

    # üîÑ Find all .gdf files in the working directory
    run_filenames = sorted([f for f in os.listdir(working_dir) if f.endswith(".gdf")])
    if not run_filenames:
        raise RuntimeError(f"üö® No GDF files found in: {working_dir}")
    print(f"üìë Found {len(run_filenames)} GDF files to analyze.")

    for run_name in run_filenames:
        run_path = os.path.join(working_dir, run_name)
        print(f"\nüß† Processing run: {run_name}")

        raw = mne.io.read_raw_gdf(run_path, preload=True)
        events, event_id = mne.events_from_annotations(raw)

        # Step 1: Preprocessing
        raw.pick_types(eeg=True)

        montage = mne.channels.make_standard_montage("standard_1020")

        # Drop mastoids
        for ch in ["M1", "M2"]:
            if ch in raw.ch_names:
                raw.drop_channels([ch])

        # Select target channels
        target_channels = [
            'FP1', 'FP2', 'F7', 'F3', 'FZ', 'F4', 'F8',
            'FC5', 'FC1', 'FC2', 'FC6',
            'T7', 'C3', 'CZ', 'C4', 'T8',
            'CP5', 'CP1', 'CP2', 'CP6',
            'P7', 'P3', 'PZ', 'P4', 'P8',
            'O1', 'OZ', 'O2',
        ]
        raw.pick_channels([ch for ch in target_channels if ch in raw.ch_names])

        raw.notch_filter(60, method="iir")
        raw.filter(config.LOWCUT, config.HIGHCUT, method="iir")
        # Step 2: Segment each trial using 769/770 ‚Üí 7691/7701
        sfreq = int(raw.info['sfreq'])
        marker_values = events[:, 2]
        marker_times = events[:, 0]

        EPOCHS_START_END = {4: 5, 8: 9}
        all_trials = []

        for start_code, end_code in EPOCHS_START_END.items():
            start_indices = np.where(marker_values == start_code)[0]
            end_indices = np.where(marker_values == end_code)[0]

            if len(start_indices) != len(end_indices):
                min_len = min(len(start_indices), len(end_indices))
                start_indices = start_indices[:min_len]
                end_indices = end_indices[:min_len]

            for s_idx, e_idx in zip(start_indices, end_indices):
                start_sample = marker_times[s_idx]
                end_sample = marker_times[e_idx]
                label = start_code  # 4 = REST, 8 = MI

                all_trials.append((start_sample, end_sample, label))

        print(f"üîé Found {len(all_trials)} valid trials.")

        # Step 3: Slide through each trial with adaptive recentering
        trial_results = []

        for trial_num, (start_sample, end_sample, label) in enumerate(all_trials):
            baseline_start_sample = max(0, int(start_sample - sfreq))  # 1s before trial
            baseline_end_sample = int(start_sample)
            baseline_data = raw.get_data(start=baseline_start_sample, stop=baseline_end_sample)
            baseline_mean = baseline_data.mean(axis=1, keepdims=True)

            data = raw.get_data(start=int(start_sample), stop=int(end_sample))
            data = data - baseline_mean  # üßº baseline correction

            n_samples = data.shape[1]
            win_samples = int(config.CLASSIFY_WINDOW / 1000 * sfreq)
            step_samples = int(1 / 16 * sfreq)

            Prev_T = None
            counter = 0
            proba_trace = []

            for i in range(0, n_samples - win_samples + 1, step_samples):
                segment = data[:, i:i + win_samples]
                raw_seg = mne.io.RawArray(segment, raw.info.copy())

                eeg = raw_seg.get_data()
                cov = (eeg @ eeg.T) / np.trace(eeg @ eeg.T)

                if config.LEDOITWOLF:
                    cov = LedoitWolf().fit(cov).covariance_
                else:
                    cov = Shrinkage(shrinkage=config.SHRINKAGE_PARAM).fit_transform(cov[np.newaxis])[0]

                if config.RECENTERING:
                    if counter == 0:
                        Prev_T = cov
                    T = geodesic_riemann(Prev_T, cov, 1 / (counter + 1))
                    Prev_T = T
                    counter += 1
                    T_inv = invsqrtm(T)
                    cov = T_inv @ cov @ T_inv.T

                cov = np.expand_dims(cov, axis=0)
                probs = decoder.predict_proba(cov)[0]

                proba_trace.append(probs)

            trial_results.append({
                "label": label,
                "proba_trace": proba_trace
            })


        print(f"‚úÖ Completed {len(trial_results)} trials with probability traces.")


if __name__ == "__main__":
    model_dir = "/home/arman-admin/Documents/NE Course project data/Subject_205_Session_002_FES_Offline_Visual"
    working_dir = "/home/arman-admin/Documents/NE Course project data/Subject_205_FES_Online/Subject_205_Session_001_FES_Online_Visual"


    main(model_dir, working_dir)
